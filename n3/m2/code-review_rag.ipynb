{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando arquivo .env para controlar variaveis de ambiente\n",
    "Para evitar exposição da chave `OPENAI_API_KEY` optei por utilizar arquivo `.env` com a informação da chave.\n",
    "\n",
    "Para seguir o mesmo método basta criar um arquivo `.env` no mesmo diretório do arquivo `code-review_rag.ipynb`.\n",
    "A importação da chave será feita através da célula abaixo que faz a instalação de um biblioteca para carregar\n",
    "os valores do arquivo `.env`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in ./venv/lib/python3.12/site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv\n",
    "import dotenv\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando Libs\n",
    "\n",
    "Neste vídeo, é demonstrado como construir um RAG para código utilizando o Jupyter Notebook. São importadas diversas bibliotecas, como langchain, chroma, openai, chat-openai, entre outras. São utilizados métodos para carregar documentos, separar linguagens de programação e criar correntes de perguntas e respostas. Também é mostrado como instalar as bibliotecas necessárias, como langchain-chroma e langchain-openai. Além disso, é feita a importação das bibliotecas os e git para trabalhar com o sistema operacional e baixar o código de exemplo diretamento do Github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.parsers import LanguageParser\n",
    "from langchain_text_splitters import Language, RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "import os\n",
    "from git import Repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando o código\n",
    "\n",
    "Neste trecho, é demonstrado como criar uma variável para definir o caminho de um repositório e baixar um código específico para análise. É feito o carregamento de arquivos Python de um diretório específico, excluindo aqueles que não seguem o padrão UTF-8. O processo envolve o uso de um loader genérico, parser de linguagem Python e definição de um threshold. Ao final, é exibido o número de documentos carregados para análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = \"./test_repo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clonar o repositório - código do langchain\n",
    "repo = Repo.clone_from(\"https://github.com/langchain-ai/langchain\", to_path=repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "475"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carregar o repositório\n",
    "loader = GenericLoader.from_filesystem(\n",
    "    repo_path + \"/libs/core/langchain_core/\",\n",
    "    glob=\"**/*\", # carregar todos os arquivos\n",
    "    suffixes=[\".py\"], # filtro para arquivos python\n",
    "    exclude=[\"**/non-utf-8-encoding.py\"], # arquivos com encondings diferentes\n",
    "    parser=LanguageParser(language=Language.PYTHON, parser_threshold=500) # \n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando documentos em Chunks\n",
    "\n",
    "Ao carregar os documentos, aplicamos o recurso text splitter para separá-los em chunks. A escolha do tamanho do chunk, como 2.000 neste caso, é crucial e varia de acordo com o tipo de documento, como código ou PDF. Na arquitetura RAG, é essencial encontrar o tamanho ideal do chunk para otimizar o processo. Testes são necessários para determinar o tamanho mais adequado, considerando a base de dados. A execução do método resultou em 1.278 chunks a partir de 410 documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1417"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separação de pedaços de documentos (chunks)\n",
    "python_spliter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=2000, chunk_overlap = 200\n",
    ")\n",
    "\n",
    "texts = python_spliter.split_documents(documents)\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método retriever\n",
    "\n",
    "Abordamos a criação do Embedding Module usando a chave de API da OpenAI, a construção do banco vetorial Chroma e a configuração do Retriever para buscar documentos relevantes. Exploramos a inicialização do ChromaDB com OpenAI Embeddings, a definição do Search Type como MMR e a especificação de Keywords como 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar um banco de dados vetorial com os textos\n",
    "db = Chroma.from_documents(texts, OpenAIEmbeddings(disallowed_special=()))\n",
    "\n",
    "# criar um retriever para pesquisar os textos - objeto buscador\n",
    "retriever = db.as_retriever(\n",
    "    search_type = \"mmr\", # teste com similaridade diferente\n",
    "    search_kwargs = {\"k\": 8}, # quantidade de textos buscados\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo o prompt e a chain\n",
    "\n",
    "Neste trecho, é explicado o uso do LLM ChatOpenAI, especialmente o modelo GPT-3.5 Turbo, com a definição de um prompt utilizando o método ChatPromptTemplate. O prompt é criado com informações do System, User e Assistant, para melhorar a resposta do modelo. É mencionada a criação de uma DocumentChain e RetrievalChain para compilar documentos e realizar a recuperação de textos. O objetivo é utilizar essas ferramentas para responder a consultas de revisão de código de forma mais eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# associar um LLM a uma variável para gerar a resposta\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\", # modelo llm\n",
    "    max_tokens=200, # máximo de tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar um chain para gerar a resposta (prompt)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\", # sistema\n",
    "        \"Você é um revisor de código experiente. Forneça informações detalhadas sobre a revisão do código e sugestões de melhorias baseadas no contexto fornecido abaixo: \\n\\n{context}\", # context\n",
    "    ),\n",
    "    (\"user\", \"{input}\"), # query\n",
    "])\n",
    "\n",
    "# compilar os docs recebidos para receber o llm e o prompt\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "# cadeia de recuperação dos textos \n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response e Recapitulando\n",
    "\n",
    "Foi destacada a importância da documentação, clareza e organização do código, além de sugestões de melhorias, como completar a documentação, incluir exemplos práticos, testes unitários e refatoração do código. Também foi mencionada a evolução da arquitetura e a resolução de problemas futuros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O código de `RunnableBinding` parece estar bem estruturado e organizado. No entanto, há algumas sugestões de melhorias e observações que podem ser consideradas:\\n\\n1. **Documentação Adequada**: Adicionar documentação detalhada e explicativa para cada método e classe, incluindo descrições claras, exemplos de uso e possíveis cenários de aplicação.\\n\\n2. **Tipagem Forte**: Certifique-se de adicionar anotações de tipo explícitas para parâmetros de método e valores de retorno, para facilitar a compreensão do código e garantir a consistência.\\n\\n3. **Tratamento de Exceções**: Considere adicionar tratamento de exceções apropriado em métodos como `backward`, `update` e outros, para lidar com possíveis erros de forma mais robusta.\\n\\n4. **Melhorias nos Métodos**: \\n   - No'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# buscador de textos passando um input específico\n",
    "response = retrieval_chain.invoke({\"input\": \"Você pode revisar e sugerir melhorias para o código de RunnableBinding\"})\n",
    "response[\"answer\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia_para_devs-NJoqudvH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
