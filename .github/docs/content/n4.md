# N√≠vel 4 - Otimizando LLMs com Fine Tuning

> Retornar ao [README.md](../../../README.md)

## Sum√°rio

- [N√≠vel 4 - Otimizando LLMs com Fine Tuning](#n√≠vel-4---otimizando-llms-com-fine-tuning)
  - [Sum√°rio](#sum√°rio)
  - [Estrutura de Pastas e Arquivos](#estrutura-de-pastas-e-arquivos)
  - [Notas e Links Importantes](#notas-e-links-importantes)
  - [Question√°rio Avaliativo](#question√°rio-avaliativo)
  - [Conceitos e Explica√ß√µes](#conceitos-e-explica√ß√µes)
    - [O que √© Fine-Tuning?](#o-que-√©-fine-tuning)
    - [√â necess√°rio fazer fine-tunning nos modelos LLMs j√° existentes?](#√©-necess√°rio-fazer-fine-tunning-nos-modelos-llms-j√°-existentes)
    - [Como deve ser o formanto dos dados para realizar o fine-tuning na OpenAI?](#como-deve-ser-o-formanto-dos-dados-para-realizar-o-fine-tuning-na-openai)
      - [Estrutura do JSONL](#estrutura-do-jsonl)
      - [Campos obrigat√≥rios](#campos-obrigat√≥rios)
      - [Exemplo de Estrutura Completa](#exemplo-de-estrutura-completa)
      - [Requisitos adicionais](#requisitos-adicionais)
    - [Modelos de Linguagem (LMs) e Modelos de Pequena Escala (SLMs)](#modelos-de-linguagem-lms-e-modelos-de-pequena-escala-slms)
    - [Fine-Tuning √© Necess√°rio para LMs e SLMs?](#fine-tuning-√©-necess√°rio-para-lms-e-slms)
      - [Quando o Fine-Tuning √© Necess√°rio](#quando-o-fine-tuning-√©-necess√°rio)
      - [Quando o Fine-Tuning N√£o √© Necess√°rio](#quando-o-fine-tuning-n√£o-√©-necess√°rio)
      - [Alternativas ao Fine-Tuning](#alternativas-ao-fine-tuning)
    - [Amazon Bedrock: Plataforma de Modelos Generativos da AWS](#amazon-bedrock-plataforma-de-modelos-generativos-da-aws)
      - [Principais Recursos do Amazon Bedrock](#principais-recursos-do-amazon-bedrock)
      - [Casos de Uso do Amazon Bedrock](#casos-de-uso-do-amazon-bedrock)
      - [Diferen√ßa entre Amazon Bedrock e Outras Solu√ß√µes](#diferen√ßa-entre-amazon-bedrock-e-outras-solu√ß√µes)
    - [Arquitetura Transformer no Contexto de Fine-Tuning](#arquitetura-transformer-no-contexto-de-fine-tuning)
      - [Principais Componentes do Transformer](#principais-componentes-do-transformer)
      - [Transformers e Fine-Tuning](#transformers-e-fine-tuning)
    - [O que √© BERT?](#o-que-√©-bert)
      - [Principais Caracter√≠sticas do BERT](#principais-caracter√≠sticas-do-bert)
      - [Varia√ß√µes do BERT](#varia√ß√µes-do-bert)
      - [Aplica√ß√µes do BERT](#aplica√ß√µes-do-bert)

## Estrutura de Pastas e Arquivos

```plaintext
üìÅn4
‚îú‚îÄüìì[dataset_prep.ipynb]
‚îú‚îÄüìì[fine_tuningBERT.ipynb]
‚îú‚îÄüìú[train_aws.jsonl]
‚îú‚îÄüìú[train.jsonl]
‚îú‚îÄüìú[validation_aws.jsonl]
‚îú‚îÄüìú[validation.jsonl]
‚îî‚îÄüìÅtask
  ‚îú‚îÄüìÅdata
  ‚îÇ ‚îú‚îÄüìú[teste.jsonl]
  ‚îÇ ‚îî‚îÄüìú[treino.jsonl]
  ‚îî‚îÄüìì[t_fine_tuning.ipynb]
```

## Notas e Links Importantes

- [Fine-Tuning OpenAI Documentation](https://platform.openai.com/docs/guides/fine-tuning)
- [Data preparation and analysis for chat model fine-tuning (Example)](https://cookbook.openai.com/examples/chat_finetuning_data_prep)
- [Example JSONL file](https://github.com/openai/openai-cookbook/blob/main/examples/data/toy_chat_fine_tuning.jsonl)

## Question√°rio Avaliativo

1. *O que √© fine-tuning em modelos de linguagem?* **Resposta:** Um ajuste de um modelo pr√©-treinado para tarefas ou dom√≠nios espec√≠ficos.

2. *Sobre fine-tuning quais das afirmativas a seguir n√£o s√£o verdadeiras. I - O fine-tuning pode ser utilizado em qualquer contexto para especializar modelos devido a seu baixo custo. II - O fine-tuning pode ajudar um modelo pr√©-treinado a se especializar em tarefas espec√≠ficas. III - O fine-tuning deve ser feito com cuidado para evitar problemas como overfitting. IV - O fine-tuning sempre substitui completamente o conhecimento adquirido no pr√©-treinamento.* **Resposta:** I e IV

3. *O que √© o Amazon Bedrock?* **Resposta:** Um servi√ßo de intelig√™ncia artificial generativa que permite criar e implementar modelos de IA personaliz√°veis usando modelos fundacionais (foundation models).

4. *Quais das afirma√ß√µes a seguir n√£o se encaixam a um Small Language Model (SLM). I - S√£o modelo de linguagem que utilizam centenas de bilh√µes de par√¢metros para resolver diversos tipos de problemas, com grande capacidade para gera√ß√£o de texto. II - S√£o modelos reduzidos que podem desempenhar muito bem em tarefas espec√≠ficas quando ajustados para esses temas. III - SLMs s√£o incapazes de realizar tarefas de linguagem natural porque n√£o possuem dados suficientes para treinamento.* **Resposta:** I e III

5. *O que √© a arquitetura Transformer?* **Resposta:** A arquitetura Transformer √© uma t√©cnica de redes neurais baseada em um mecanismo de aten√ß√£o, projetada para lidar com sequ√™ncias de dados, como texto, sem usar estruturas sequenciais tradicionais.

6. *O que √© o BERT?* **Resposta:** BERT √© um modelo de linguagem baseado em redes neurais, desenvolvido pelo Google, para entender melhor o contexto de palavras em frases.

## Conceitos e Explica√ß√µes

> [Slides](../pdf/n4.pdf) das aulas
>
> [Desafio e Solu√ß√£o](./tasks/cn4.md)

### O que √© Fine-Tuning?

Fine-tuning, ou ajuste fino, √© o processo de adaptar um modelo de intelig√™ncia artificial que j√° foi treinado em uma grande quantidade de dados para uma tarefa ou dom√≠nio espec√≠fico. Em vez de treinar um modelo do zero, aproveita-se o conhecimento previamente adquirido (por exemplo, sobre linguagem natural, imagens, etc.) e realiza-se um refinamento com um conjunto de dados especializado. Esse processo permite que o modelo se torne mais eficiente e preciso para tarefas espec√≠ficas, como an√°lises de sentimentos, tradu√ß√£o de idiomas ou diagn√≥stico m√©dico, por exemplo.

### √â necess√°rio fazer fine-tunning nos modelos LLMs j√° existentes?

N√£o √© estritamente necess√°rio fazer fine-tuning em modelos de *Large Language Models* (LLMs) j√° existentes, pois muitos deles, como GPT-4, LLaMA e Mistral, j√° foram treinados com grandes quantidades de dados e possuem uma capacidade geral suficiente para diversas tarefas. No entanto, h√° casos em que o fine-tuning pode ser vantajoso:

1. **Dom√≠nios espec√≠ficos**: Se a aplica√ß√£o requer conhecimento especializado (como medicina, direito ou finan√ßas), um ajuste fino com dados espec√≠ficos pode melhorar a precis√£o das respostas.

2. **Adapta√ß√£o a um estilo ou tom espec√≠fico**: Algumas aplica√ß√µes podem exigir respostas mais formais, t√©cnicas ou adaptadas a um p√∫blico-alvo espec√≠fico.

3. **Aprimoramento de desempenho em tarefas personalizadas**: Se um LLM precisa lidar com instru√ß√µes ou formatos muito particulares, um treinamento adicional pode melhorar sua efic√°cia.

4. **Seguran√ßa e conformidade**: O fine-tuning pode ser usado para evitar que o modelo gere respostas inadequadas ou tendenciosas dentro de um ambiente corporativo ou regulamentado.

Caso o fine-tuning n√£o seja vi√°vel ou necess√°rio, alternativas como *prompt engineering* (ajuste das entradas para obter melhores sa√≠das) e *RAG (Retrieval-Augmented Generation)* podem ser suficientes para personalizar a intera√ß√£o com o modelo sem precisar modific√°-lo diretamente.

### Como deve ser o formanto dos dados para realizar o fine-tuning na OpenAI?

Para realizar o **fine-tuning em modelos da OpenAI**, como o `GPT-3.5` ou `GPT-4`, √© necess√°rio fornecer um conjunto de dados em **formato JSONL (JSON Lines)**.

#### Estrutura do JSONL

Cada linha do arquivo deve conter um par de exemplos de **prompt** e **resposta** (input/output), como no exemplo abaixo:

```json
{"messages": [{"role": "system", "content": "Voc√™ √© um assistente de IA especializado em finan√ßas."}, {"role": "user", "content": "Qual √© o melhor investimento a longo prazo?"}, {"role": "assistant", "content": "O investimento a longo prazo depende do seu perfil de risco, mas a√ß√µes e fundos de √≠ndice s√£o boas op√ß√µes."}]}
{"messages": [{"role": "user", "content": "Explique o conceito de infla√ß√£o."}, {"role": "assistant", "content": "A infla√ß√£o √© o aumento geral dos pre√ßos de bens e servi√ßos ao longo do tempo."}]}
```

#### Campos obrigat√≥rios

- `role`: Define quem est√° falando. Pode ser `"system"` (para orientar o comportamento do modelo), `"user"` (entrada do usu√°rio) ou `"assistant"` (resposta do modelo).
- `content`: O conte√∫do da mensagem.

#### Exemplo de Estrutura Completa

```json
{"messages": [{"role": "system", "content": "Voc√™ √© um tutor de programa√ß√£o em Python."}, {"role": "user", "content": "Como fa√ßo um loop for em Python?"}, {"role": "assistant", "content": "Voc√™ pode usar a estrutura `for` assim: `for i in range(10): print(i)`."}]}
```

#### Requisitos adicionais

- O arquivo deve conter **pelo menos 100 exemplos** para treinar o modelo.
- Cada exemplo deve ser **claro e conciso**, com foco na tarefa espec√≠fica que voc√™ deseja melhorar.
- O arquivo JSONL **n√£o pode conter erros de sintaxe**.

### Modelos de Linguagem (LMs) e Modelos de Pequena Escala (SLMs)

- **LMs (Language Models, Modelos de Linguagem)**:  
  S√£o modelos baseados em intelig√™ncia artificial treinados para processar e gerar texto. Eles aprendem padr√µes a partir de grandes conjuntos de dados textuais e podem ser usados para diversas aplica√ß√µes, como tradu√ß√£o autom√°tica, chatbots e gera√ß√£o de c√≥digo.

- **SLMs (Small Language Models, Modelos de Linguagem Pequenos)**:  
  S√£o uma subcategoria de modelos de linguagem que possuem um tamanho reduzido em compara√ß√£o com os grandes modelos (LLMs - Large Language Models). Eles s√£o projetados para serem mais eficientes, consumirem menos recursos e rodarem em dispositivos com menor capacidade computacional. Apesar de menores, ainda conseguem desempenhar tarefas de NLP (Processamento de Linguagem Natural) de forma eficaz para aplica√ß√µes espec√≠ficas.

Os SLMs s√£o √∫teis quando h√° restri√ß√µes de hardware, necessidade de execu√ß√£o local ou quando um modelo grande n√£o √© necess√°rio para determinada tarefa.

### Fine-Tuning √© Necess√°rio para LMs e SLMs?  

Nem sempre. O fine-tuning √© uma t√©cnica √∫til, mas a necessidade dele depende do caso de uso e da capacidade do modelo pr√©-treinado.  

#### Quando o Fine-Tuning √© Necess√°rio

O fine-tuning √© recomendado quando:  

- O modelo precisa se especializar em um dom√≠nio espec√≠fico (ex.: medicina, direito, engenharia).  
- O modelo deve seguir um tom ou estilo particular.  
- H√° necessidade de adapta√ß√£o para um idioma ou contexto espec√≠fico n√£o bem representado no pr√©-treinamento.  

#### Quando o Fine-Tuning N√£o √© Necess√°rio

O fine-tuning pode ser dispens√°vel quando:  

- O modelo j√° atende bem √† tarefa apenas com ajustes via *prompt engineering*.  
- O modelo √© pequeno e voltado para aplica√ß√µes gen√©ricas.  
- O custo computacional do fine-tuning n√£o compensa os ganhos esperados.  

#### Alternativas ao Fine-Tuning

- **Prompt Engineering**: Ajuste do formato do prompt para guiar a resposta do modelo sem modificar os pesos da rede.  
- **LoRA (Low-Rank Adaptation)**: Treinamento eficiente em poucos par√¢metros para adapta√ß√£o r√°pida.  
- **Adapter Layers**: Camadas adicionais trein√°veis sobre o modelo base.  

Assim, embora o fine-tuning seja √∫til, ele n√£o √© um requisito absoluto para todos os LMs e SLMs.

### Amazon Bedrock: Plataforma de Modelos Generativos da AWS

O **Amazon Bedrock** √© um servi√ßo da AWS que permite aos desenvolvedores **criar, personalizar e implantar aplica√ß√µes de intelig√™ncia artificial generativa** usando modelos fundacionais (*foundation models* ‚Äì FMs) de diferentes provedores, sem a necessidade de gerenciar a infraestrutura subjacente.  

#### Principais Recursos do Amazon Bedrock

1. **Acesso a Modelos Fundacionais (FMs)**  
   - Oferece suporte a diversos modelos de IA de diferentes empresas, incluindo:  
     - **Anthropic** (Claude)  
     - **AI21 Labs** (Jurassic)  
     - **Stability AI** (Stable Diffusion)  
     - **Meta** (LLaMA)  
     - **Cohere**  
     - **Amazon Titan** (modelos propriet√°rios da AWS)  

2. **Fine-Tuning e Customiza√ß√£o**  
   - Permite o **ajuste fino (fine-tuning)** dos modelos com dados espec√≠ficos da empresa, sem necessidade de treinar um modelo do zero.  

3. **Integra√ß√£o com Servi√ßos AWS**  
   - F√°cil conex√£o com servi√ßos como **Amazon S3, Lambda, SageMaker, Bedrock Agents** e **IAM** para controle de acesso e gerenciamento.  

4. **Gera√ß√£o de Imagens e Texto**  
   - Suporte a modelos para **conversa√ß√£o, resumo de texto, gera√ß√£o de c√≥digo e cria√ß√£o de imagens**.  

5. **API Simples e Escal√°vel**  
   - Permite integrar os modelos em aplica√ß√µes por meio de APIs sem precisar configurar servidores ou GPUs.  

#### Casos de Uso do Amazon Bedrock

- **Chatbots e Assistentes Virtuais**  
- **Automa√ß√£o de Documentos** (tradu√ß√£o, resumo, gera√ß√£o de contratos)  
- **Gera√ß√£o de C√≥digo e An√°lises de Dados**  
- **Cria√ß√£o de Imagens e Conte√∫dos Visuais**  
- **Personaliza√ß√£o de Experi√™ncia do Cliente**  

#### Diferen√ßa entre Amazon Bedrock e Outras Solu√ß√µes

| Caracter√≠stica | Amazon Bedrock | OpenAI API | Google Vertex AI |
|--------------|--------------|-------------|-----------------|
| **Modelos dispon√≠veis** | V√°rios provedores | OpenAI (GPT-4, 3.5) | Modelos da Google (PaLM, Gemini) |
| **Fine-Tuning** | Sim | Sim | Sim |
| **Infraestrutura gerenciada** | Sim (AWS) | Sim (Azure para GPT-4) | Sim (Google Cloud) |
| **Gera√ß√£o de Imagem** | Sim (Stable Diffusion) | Sim (DALL¬∑E) | Sim (Imagen) |

### Arquitetura Transformer no Contexto de Fine-Tuning

A **arquitetura Transformer** √© um modelo de deep learning baseado em **mecanismos de aten√ß√£o** (*self-attention*), sendo a base de modelos avan√ßados de IA, como **GPT, BERT, LLaMA e Claude**. Esse tipo de arquitetura permite processar **dados sequenciais** (como textos) de forma **paralela e eficiente**, tornando-a fundamental para tarefas como **tradu√ß√£o autom√°tica, resumo de texto e chatbots**.

A **arquitetura Transformer** revolucionou a IA ao permitir que modelos como GPT-4, BERT e LLaMA processem grandes quantidades de texto de maneira eficiente. No contexto de **fine-tuning**, ela possibilita **ajustar modelos pr√©-treinados** para tarefas espec√≠ficas, reduzindo tempo de treinamento e necessidade de dados.

#### Principais Componentes do Transformer

1. **Mecanismo de Self-Attention**  
   - Permite que cada palavra (ou *token*) analise todas as outras palavras da sequ√™ncia para capturar **rela√ß√µes contextuais**, independentemente da dist√¢ncia.  

2. **Codifica√ß√£o Posicional**  
   - Como a arquitetura Transformer n√£o processa dados sequencialmente (como RNNs), ela usa embeddings posicionais para manter a **ordem das palavras**.  

3. **Camadas de Normaliza√ß√£o e Feedforward**  
   - Ap√≥s a aten√ß√£o, os tokens passam por **camadas de normaliza√ß√£o** e **redes neurais feedforward**, garantindo estabilidade no treinamento.  

4. **Estrutura Encoder-Decoder (Opcional)**  
   - Modelos como **BERT** usam apenas o **encoder** (para compreens√£o de texto), enquanto **GPT** usa apenas o **decoder** (para gera√ß√£o de texto).  

#### Transformers e Fine-Tuning

Na pr√°tica, **o fine-tuning de um modelo Transformer** significa treinar um modelo j√° pr√©-treinado em uma grande base de dados (como GPT ou BERT) usando um **conjunto de dados especializado**. Isso permite:  

- **Especializa√ß√£o para um dom√≠nio espec√≠fico** (ex.: direito, medicina).  
- **Ajuste de respostas para uma aplica√ß√£o espec√≠fica** (ex.: chatbot corporativo).  
- **Melhoria da precis√£o para tarefas espec√≠ficas**, como an√°lise de sentimentos ou resumo de textos.  

O fine-tuning geralmente ocorre **congelando algumas camadas do modelo original** e treinando apenas as √∫ltimas camadas para evitar sobreajuste (*overfitting*).  

### O que √© BERT?

O **BERT (Bidirectional Encoder Representations from Transformers)** √© um modelo de **aprendizado profundo baseado na arquitetura Transformer**, desenvolvido pelo Google AI em 2018. Ele √© projetado para **compreens√£o de linguagem natural (NLU)** e se destaca por processar texto de forma **bidirecional**, ou seja, analisando o contexto **antes e depois** de cada palavra.  

O **BERT √© um dos modelos mais importantes para NLP**, revolucionando a forma como m√°quinas compreendem textos. Sua **arquitetura bidirecional** e capacidade de **fine-tuning** permitem aplica√ß√µes eficientes e precisas em diversas √°reas, desde **buscas na web at√© an√°lise de dados empresariais**.

#### Principais Caracter√≠sticas do BERT

1. **Aprendizado Bidirecional**  
   - Diferente de modelos anteriores, como RNNs e LSTMs, que leem o texto de forma sequencial, o BERT **l√™ a senten√ßa inteira de uma vez**, permitindo uma compreens√£o mais precisa do significado das palavras.  

2. **Pr√©-Treinamento em Grandes Bases de Dados**  
   - O BERT √© pr√©-treinado em **grandes quantidades de texto**, como a Wikipedia e o corpus BooksCorpus, aprendendo representa√ß√µes lingu√≠sticas gen√©ricas.  

3. **T√©cnicas de Pr√©-Treinamento**  
   - **Masked Language Model (MLM):** Durante o treinamento, partes do texto s√£o mascaradas e o modelo tenta prever as palavras ocultas.  
   - **Next Sentence Prediction (NSP):** O modelo aprende a prever se uma frase segue outra no texto, ajudando na compreens√£o de contexto.  

4. **Fine-Tuning para Tarefas Espec√≠ficas**  
   - Ap√≥s o pr√©-treinamento, o BERT pode ser refinado (**fine-tuning**) para tarefas como **an√°lise de sentimentos, perguntas e respostas, e classifica√ß√£o de texto**.  

#### Varia√ß√µes do BERT

Ap√≥s o lan√ßamento do BERT original, v√°rias vers√µes otimizadas foram criadas:  

- **DistilBERT** ‚Äì Modelo menor e mais r√°pido, mantendo boa precis√£o.  
- **RoBERTa** ‚Äì Vers√£o aprimorada com mais dados de treinamento e sem NSP.  
- **ALBERT** ‚Äì Vers√£o mais compacta e eficiente para infer√™ncia.  

#### Aplica√ß√µes do BERT

- **Motores de busca (Google Search)** ‚Äì Melhor compreens√£o das inten√ß√µes do usu√°rio.  
- **Chatbots e Assistentes Virtuais** ‚Äì Melhor interpreta√ß√£o de comandos em linguagem natural.  
- **Classifica√ß√£o de Sentimentos** ‚Äì An√°lise de opini√µes em redes sociais e reviews.  
- **Perguntas e Respostas (Q&A)** ‚Äì Extra√ß√£o de respostas a partir de textos longos.  
